{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**:\n",
    "- Binary Classifier (BC)\n",
    "- Random Forest (RF)\n",
    "- Neural Network (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score, make_scorer, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets and Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BC & RF: features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = pd.read_csv('~data/feature_extraction.csv')\n",
    "df_feature = df_feature.dropna(how='all', subset=df_feature.columns[2:])\n",
    "df_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN: sites_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>TUR</th>\n",
       "      <th>SPM</th>\n",
       "      <th>CHL</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>55.189352</td>\n",
       "      <td>-1.519043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newbiggin North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>55.189352</td>\n",
       "      <td>-1.517296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newbiggin North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>55.189352</td>\n",
       "      <td>-1.515549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newbiggin North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>55.189352</td>\n",
       "      <td>-1.513802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newbiggin North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>55.189352</td>\n",
       "      <td>-1.512055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newbiggin North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331105</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>50.277315</td>\n",
       "      <td>-3.893256</td>\n",
       "      <td>2.006134</td>\n",
       "      <td>1.186131</td>\n",
       "      <td>1.828091</td>\n",
       "      <td>Bigbury-on-Sea South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331106</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>50.277315</td>\n",
       "      <td>-3.891509</td>\n",
       "      <td>0.708182</td>\n",
       "      <td>0.406647</td>\n",
       "      <td>1.046769</td>\n",
       "      <td>Bigbury-on-Sea South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331107</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>50.277315</td>\n",
       "      <td>-3.889762</td>\n",
       "      <td>1.258156</td>\n",
       "      <td>0.729469</td>\n",
       "      <td>1.327342</td>\n",
       "      <td>Bigbury-on-Sea South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331108</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>50.277315</td>\n",
       "      <td>-3.888015</td>\n",
       "      <td>1.037095</td>\n",
       "      <td>0.598882</td>\n",
       "      <td>1.254974</td>\n",
       "      <td>Bigbury-on-Sea South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331109</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>50.277315</td>\n",
       "      <td>-3.886268</td>\n",
       "      <td>0.563590</td>\n",
       "      <td>0.323039</td>\n",
       "      <td>1.018072</td>\n",
       "      <td>Bigbury-on-Sea South</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12331110 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                time        lat       lon       TUR       SPM       CHL   \n",
       "0         2022-03-01  55.189352 -1.519043       NaN       NaN       NaN  \\\n",
       "1         2022-03-01  55.189352 -1.517296       NaN       NaN       NaN   \n",
       "2         2022-03-01  55.189352 -1.515549       NaN       NaN       NaN   \n",
       "3         2022-03-01  55.189352 -1.513802       NaN       NaN       NaN   \n",
       "4         2022-03-01  55.189352 -1.512055       NaN       NaN       NaN   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "12331105  2022-10-31  50.277315 -3.893256  2.006134  1.186131  1.828091   \n",
       "12331106  2022-10-31  50.277315 -3.891509  0.708182  0.406647  1.046769   \n",
       "12331107  2022-10-31  50.277315 -3.889762  1.258156  0.729469  1.327342   \n",
       "12331108  2022-10-31  50.277315 -3.888015  1.037095  0.598882  1.254974   \n",
       "12331109  2022-10-31  50.277315 -3.886268  0.563590  0.323039  1.018072   \n",
       "\n",
       "                          site  \n",
       "0              Newbiggin North  \n",
       "1              Newbiggin North  \n",
       "2              Newbiggin North  \n",
       "3              Newbiggin North  \n",
       "4              Newbiggin North  \n",
       "...                        ...  \n",
       "12331105  Bigbury-on-Sea South  \n",
       "12331106  Bigbury-on-Sea South  \n",
       "12331107  Bigbury-on-Sea South  \n",
       "12331108  Bigbury-on-Sea South  \n",
       "12331109  Bigbury-on-Sea South  \n",
       "\n",
       "[12331110 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_data = pd.read_csv(\"~data/sites_data_11x11.csv\")\n",
    "sites_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time           0\n",
       "lat            0\n",
       "lon            0\n",
       "TUR     10838900\n",
       "SPM     10838900\n",
       "CHL     10838900\n",
       "site           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Null Values with 0, as we cannot have missing values in the tensors for neural network\n",
    "# Later we will remove time, site pairs where all values are 0\n",
    "\n",
    "sites_data.fillna(value=-10, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All: Pollution Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>time</th>\n",
       "      <th>warning</th>\n",
       "      <th>riskLevelLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ainsdale</td>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>Pollution RIsk Forecasts will start soon</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ainsdale</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>Pollution RIsk Forecasts will start soon</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ainsdale</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Pollution RIsk Forecasts will start soon</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ainsdale</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>No warnings in place</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ainsdale</td>\n",
       "      <td>2022-05-05</td>\n",
       "      <td>No warnings in place</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63573</th>\n",
       "      <td>Yaverland</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63574</th>\n",
       "      <td>Yaverland</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63575</th>\n",
       "      <td>Yaverland</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63576</th>\n",
       "      <td>Yaverland</td>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63577</th>\n",
       "      <td>Yaverland</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63578 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site        time                                   warning   \n",
       "0       Ainsdale  2022-04-28  Pollution RIsk Forecasts will start soon  \\\n",
       "1       Ainsdale  2022-04-29  Pollution RIsk Forecasts will start soon   \n",
       "2       Ainsdale  2022-04-30  Pollution RIsk Forecasts will start soon   \n",
       "3       Ainsdale  2022-05-04                      No warnings in place   \n",
       "4       Ainsdale  2022-05-05                      No warnings in place   \n",
       "...          ...         ...                                       ...   \n",
       "63573  Yaverland  2022-09-26           No pollution incidents reported   \n",
       "63574  Yaverland  2022-09-27           No pollution incidents reported   \n",
       "63575  Yaverland  2022-09-28           No pollution incidents reported   \n",
       "63576  Yaverland  2022-09-29           No pollution incidents reported   \n",
       "63577  Yaverland  2022-09-30           No pollution incidents reported   \n",
       "\n",
       "      riskLevelLabel  \n",
       "0             normal  \n",
       "1             normal  \n",
       "2             normal  \n",
       "3             normal  \n",
       "4             normal  \n",
       "...              ...  \n",
       "63573         normal  \n",
       "63574         normal  \n",
       "63575         normal  \n",
       "63576         normal  \n",
       "63577         normal  \n",
       "\n",
       "[63578 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "riskforecasting = pd.read_csv('~data/pollution_risk_forecasting.csv')\n",
    "riskforecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation and Further Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace NaNs with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_values_with_mean(row, feature, dimensions):\n",
    "    if pd.isnull(row).any():\n",
    "        for dim in dimensions:\n",
    "            if pd.isna(row[f\"{feature}_{dim}x{dim}_median\"]):\n",
    "                available_medians = row[[f\"{feature}_{i}x{i}_median\" for i in dimensions if not pd.isna(row[f\"{feature}_{i}x{i}_median\"])]]\n",
    "                row[f\"{feature}_{dim}x{dim}_median\"] = available_medians.mean()\n",
    "\n",
    "            if pd.isna(row[f\"{feature}_{dim}x{dim}_mean\"]):\n",
    "                available_means = row[[f\"{feature}_{i}x{i}_mean\" for i in dimensions if not pd.isna(row[f\"{feature}_{i}x{i}_mean\"])]]\n",
    "                row[f\"{feature}_{dim}x{dim}_mean\"] = available_means.mean()\n",
    "\n",
    "            if pd.isna(row[f\"{feature}_{dim}x{dim}_q1\"]):\n",
    "                available_q1s = row[[f\"{feature}_{i}x{i}_q1\" for i in dimensions if not pd.isna(row[f\"{feature}_{i}x{i}_q1\"])]]\n",
    "                row[f\"{feature}_{dim}x{dim}_q1\"] = available_q1s.mean()\n",
    "\n",
    "            if pd.isna(row[f\"{feature}_{dim}x{dim}_q3\"]):\n",
    "                available_q3s = row[[f\"{feature}_{i}x{i}_q3\" for i in dimensions if not pd.isna(row[f\"{feature}_{i}x{i}_q3\"])]]\n",
    "                row[f\"{feature}_{dim}x{dim}_q3\"] = available_q3s.mean()\n",
    "    return row\n",
    "\n",
    "# apply the function to the DataFrame\n",
    "dimensions = range(1, 12, 2)\n",
    "df_feature_mean = df_feature\n",
    "for feature in [\"TUR\", \"SPM\", \"CHL\"]:\n",
    "    df_feature_mean = df_feature_mean.apply(fill_na_values_with_mean, axis=1, args=(feature, dimensions))\n",
    "df_feature_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_feature_mean, riskforecasting[['site', 'time', 'riskLevelLabel']], on=['site', 'time'])\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged\n",
    "df[\"riskLevelLabel\"].replace({\"normal\": 0, \"increased\": 1}, inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df.iloc[:, 2:-1] = scaler.fit_transform(df.iloc[:, 2:-1])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN: Combine Datasets to Create Input Dataset\n",
    "For every site (430) and time (237), create a 11 x 11 x 3 tensor, each corresponding to one risk level label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.17 s, sys: 506 ms, total: 6.68 s\n",
      "Wall time: 6.77 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TUR</th>\n",
       "      <th>SPM</th>\n",
       "      <th>CHL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022-03-01</th>\n",
       "      <th>Ainsdale</th>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allonby</th>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allonby South</th>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amble Links</th>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anderby</th>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022-10-31</th>\n",
       "      <th>Withernsea</th>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wolvercote Mill Stream</th>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Woolacombe Village</th>\n",
       "      <td>[[5.9864016, 25.982555, -10.0, -10.0, -10.0, -...</td>\n",
       "      <td>[[3.564524, 16.43204, -10.0, -10.0, -10.0, -10...</td>\n",
       "      <td>[[6.564089, 6.803925, -10.0, -10.0, -10.0, -10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Worthing</th>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yaverland</th>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101910 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 TUR   \n",
       "time       site                                                                        \n",
       "2022-03-01 Ainsdale                [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \\\n",
       "           Allonby                 [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Allonby South           [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Amble Links             [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Anderby                 [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "...                                                                              ...   \n",
       "2022-10-31 Withernsea              [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Wolvercote Mill Stream  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Woolacombe Village      [[5.9864016, 25.982555, -10.0, -10.0, -10.0, -...   \n",
       "           Worthing                [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Yaverland               [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "\n",
       "                                                                                 SPM   \n",
       "time       site                                                                        \n",
       "2022-03-01 Ainsdale                [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \\\n",
       "           Allonby                 [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Allonby South           [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Amble Links             [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Anderby                 [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "...                                                                              ...   \n",
       "2022-10-31 Withernsea              [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Wolvercote Mill Stream  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Woolacombe Village      [[3.564524, 16.43204, -10.0, -10.0, -10.0, -10...   \n",
       "           Worthing                [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "           Yaverland               [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "\n",
       "                                                                                 CHL  \n",
       "time       site                                                                       \n",
       "2022-03-01 Ainsdale                [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \n",
       "           Allonby                 [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \n",
       "           Allonby South           [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \n",
       "           Amble Links             [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \n",
       "           Anderby                 [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \n",
       "...                                                                              ...  \n",
       "2022-10-31 Withernsea              [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \n",
       "           Wolvercote Mill Stream  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \n",
       "           Woolacombe Village      [[6.564089, 6.803925, -10.0, -10.0, -10.0, -10...  \n",
       "           Worthing                [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \n",
       "           Yaverland               [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...  \n",
       "\n",
       "[101910 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def chl_to_array(chl_values):\n",
    "    # Not 100% sure if this reshapes according to lat/lon (though it does not matter if we perform the same operation every time?)\n",
    "    return np.array(chl_values).reshape(11, 11)\n",
    "\n",
    "def get_features_data(sites_data, features_list):\n",
    "    '''\n",
    "    input: \n",
    "        - sites_data (pd.DataFrame):\n",
    "            - dataframe where each row contains feature values for a time, site and coordinate\n",
    "        - features_list (list):\n",
    "            - list of strings of features to use\n",
    "            \n",
    "    output:\n",
    "        - features data (pd.DataFrame)\n",
    "            - row: data for every time and site pair\n",
    "            - column: features\n",
    "            - entries: np.array of shape 11x11\n",
    "    '''\n",
    "    dfs = []\n",
    "    for feature in features_list:\n",
    "        df = pd.DataFrame(sites_data.groupby(['time', 'site'])[feature].apply(chl_to_array))\n",
    "        dfs.append(df)\n",
    "    input_data = reduce(lambda  left,right: pd.merge(left,right,on=['time', 'site'],how='outer'), dfs)\n",
    "    \n",
    "    return input_data\n",
    "\n",
    "features_df = get_features_data(sites_data, ['TUR', 'SPM', 'CHL'])\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging datasets. Merge on riskforecasting (only add CHL values if we have riskLevellabel)\n",
    "input_data = features_df.merge(riskforecasting, how='right', left_on=['time', 'site'], right_on=['time', 'site'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2022-07-23    421\n",
       "2022-07-25    421\n",
       "2022-04-06      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing data check. \n",
    "# Data missing for 07-23 and 07-25 for all sites - No satellite data\n",
    "\n",
    "input_data[input_data['CHL'].isnull()]['time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>site</th>\n",
       "      <th>TUR</th>\n",
       "      <th>SPM</th>\n",
       "      <th>CHL</th>\n",
       "      <th>warning</th>\n",
       "      <th>riskLevelLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53163</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>Summerleaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of reduced water quality due to sewage</td>\n",
       "      <td>increased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time         site  TUR  SPM  CHL   \n",
       "53163  2022-04-06  Summerleaze  NaN  NaN  NaN  \\\n",
       "\n",
       "                                           warning riskLevelLabel  \n",
       "53163  Risk of reduced water quality due to sewage      increased  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other missing values to look into - why do we have risk level labels but not satellite data when merging? Naming issue?\n",
    "\n",
    "input_data[(input_data['CHL'].isnull()) & (input_data['time'] != '2022-07-23') & (input_data['time'] != '2022-07-25')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62735, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NA values for now as there are not that many of them\n",
    "input_data.dropna(inplace=True)\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>site</th>\n",
       "      <th>TUR</th>\n",
       "      <th>SPM</th>\n",
       "      <th>CHL</th>\n",
       "      <th>warning</th>\n",
       "      <th>riskLevelLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>Ainsdale</td>\n",
       "      <td>[[3.0191753, 4.718409, 18.93536, 31.146648, 17...</td>\n",
       "      <td>[[1.7733235, 2.7514145, 11.544017, 19.844542, ...</td>\n",
       "      <td>[[3.7512763, 5.389326, 19.847187, 21.874485, 5...</td>\n",
       "      <td>Pollution RIsk Forecasts will start soon</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>Ainsdale</td>\n",
       "      <td>[[6.075095, 8.419083, 17.229292, 32.485336, 56...</td>\n",
       "      <td>[[3.7166793, 5.1792426, 10.841286, 22.20052, 5...</td>\n",
       "      <td>[[7.8970146, 8.904125, 19.88592, 23.188456, 5....</td>\n",
       "      <td>No warnings in place</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-05-07</td>\n",
       "      <td>Ainsdale</td>\n",
       "      <td>[[7.0757475, 8.779541, 17.503372, 31.796015, 8...</td>\n",
       "      <td>[[4.3843403, 5.4292417, 11.049892, 21.979761, ...</td>\n",
       "      <td>[[7.3157673, 8.303483, 17.746412, 20.563904, 4...</td>\n",
       "      <td>No warnings in place</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>Ainsdale</td>\n",
       "      <td>[[11.064278, 13.916054, 24.395746, 46.244003, ...</td>\n",
       "      <td>[[6.9718647, 8.925689, 15.609535, 33.33457, 68...</td>\n",
       "      <td>[[8.789717, 9.66038, 23.01165, 27.012566, 5.88...</td>\n",
       "      <td>No warnings in place</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>Ainsdale</td>\n",
       "      <td>[[13.135989, 17.599348, 28.951145, 57.160267, ...</td>\n",
       "      <td>[[8.290485, 11.462988, 18.59951, 41.832813, 51...</td>\n",
       "      <td>[[9.688214, 10.983141, 27.479614, 32.686024, 6...</td>\n",
       "      <td>No warnings in place</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63555</th>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>Yaverland</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63560</th>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>Yaverland</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63565</th>\n",
       "      <td>2022-09-18</td>\n",
       "      <td>Yaverland</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63570</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>Yaverland</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63575</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>Yaverland</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>[[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17762 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time       site   \n",
       "1      2022-04-29   Ainsdale  \\\n",
       "3      2022-05-04   Ainsdale   \n",
       "6      2022-05-07   Ainsdale   \n",
       "11     2022-05-12   Ainsdale   \n",
       "13     2022-05-14   Ainsdale   \n",
       "...           ...        ...   \n",
       "63555  2022-09-08  Yaverland   \n",
       "63560  2022-09-13  Yaverland   \n",
       "63565  2022-09-18  Yaverland   \n",
       "63570  2022-09-23  Yaverland   \n",
       "63575  2022-09-28  Yaverland   \n",
       "\n",
       "                                                     TUR   \n",
       "1      [[3.0191753, 4.718409, 18.93536, 31.146648, 17...  \\\n",
       "3      [[6.075095, 8.419083, 17.229292, 32.485336, 56...   \n",
       "6      [[7.0757475, 8.779541, 17.503372, 31.796015, 8...   \n",
       "11     [[11.064278, 13.916054, 24.395746, 46.244003, ...   \n",
       "13     [[13.135989, 17.599348, 28.951145, 57.160267, ...   \n",
       "...                                                  ...   \n",
       "63555  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63560  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63565  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63570  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63575  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "\n",
       "                                                     SPM   \n",
       "1      [[1.7733235, 2.7514145, 11.544017, 19.844542, ...  \\\n",
       "3      [[3.7166793, 5.1792426, 10.841286, 22.20052, 5...   \n",
       "6      [[4.3843403, 5.4292417, 11.049892, 21.979761, ...   \n",
       "11     [[6.9718647, 8.925689, 15.609535, 33.33457, 68...   \n",
       "13     [[8.290485, 11.462988, 18.59951, 41.832813, 51...   \n",
       "...                                                  ...   \n",
       "63555  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63560  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63565  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63570  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63575  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "\n",
       "                                                     CHL   \n",
       "1      [[3.7512763, 5.389326, 19.847187, 21.874485, 5...  \\\n",
       "3      [[7.8970146, 8.904125, 19.88592, 23.188456, 5....   \n",
       "6      [[7.3157673, 8.303483, 17.746412, 20.563904, 4...   \n",
       "11     [[8.789717, 9.66038, 23.01165, 27.012566, 5.88...   \n",
       "13     [[9.688214, 10.983141, 27.479614, 32.686024, 6...   \n",
       "...                                                  ...   \n",
       "63555  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63560  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63565  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63570  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "63575  [[-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -1...   \n",
       "\n",
       "                                        warning riskLevelLabel  \n",
       "1      Pollution RIsk Forecasts will start soon         normal  \n",
       "3                          No warnings in place         normal  \n",
       "6                          No warnings in place         normal  \n",
       "11                         No warnings in place         normal  \n",
       "13                         No warnings in place         normal  \n",
       "...                                         ...            ...  \n",
       "63555           No pollution incidents reported         normal  \n",
       "63560           No pollution incidents reported         normal  \n",
       "63565           No pollution incidents reported         normal  \n",
       "63570           No pollution incidents reported         normal  \n",
       "63575           No pollution incidents reported         normal  \n",
       "\n",
       "[17762 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where everything is 0 (i.e. all missing values)\n",
    "def has_nonzero(arr):\n",
    "    return np.any(arr != -10)\n",
    "\n",
    "input_data = input_data[input_data['CHL'].apply(has_nonzero)]\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split\n",
    "- Pick time-site pairs to use as train data and test data\n",
    "- Potential for implementing cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53796</th>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>Tankerton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38563</th>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>Porthluney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29452</th>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>Margate The Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44371</th>\n",
       "      <td>2022-08-27</td>\n",
       "      <td>Scarborough North Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>Fleetwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>Bournemouth Alum Chine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>Amble Links</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>Crackington Haven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49602</th>\n",
       "      <td>2022-07-03</td>\n",
       "      <td>Slapton Sands Torcross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47638</th>\n",
       "      <td>2022-07-02</td>\n",
       "      <td>Sheerness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3552 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time                    site\n",
       "53796  2022-05-28               Tankerton\n",
       "38563  2022-06-21              Porthluney\n",
       "29452  2022-04-28         Margate The Bay\n",
       "44371  2022-08-27   Scarborough North Bay\n",
       "18572  2022-09-29               Fleetwood\n",
       "...           ...                     ...\n",
       "4681   2022-09-28  Bournemouth Alum Chine\n",
       "417    2022-08-25             Amble Links\n",
       "12837  2022-09-26       Crackington Haven\n",
       "49602  2022-07-03  Slapton Sands Torcross\n",
       "47638  2022-07-02               Sheerness\n",
       "\n",
       "[3552 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_site_pairs = input_data[['time', 'site']]\n",
    "\n",
    "# 80/20 split\n",
    "time_site_pairs_test = time_site_pairs.sample(frac=.2, random_state=42)\n",
    "time_site_pairs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>Ainsdale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-05-07</td>\n",
       "      <td>Ainsdale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>Ainsdale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>Ainsdale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>Ainsdale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63532</th>\n",
       "      <td>2022-08-14</td>\n",
       "      <td>Yaverland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63537</th>\n",
       "      <td>2022-08-19</td>\n",
       "      <td>Yaverland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63546</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>Yaverland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63565</th>\n",
       "      <td>2022-09-18</td>\n",
       "      <td>Yaverland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63575</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>Yaverland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14210 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time       site\n",
       "3      2022-05-04   Ainsdale\n",
       "6      2022-05-07   Ainsdale\n",
       "13     2022-05-14   Ainsdale\n",
       "21     2022-05-22   Ainsdale\n",
       "23     2022-05-24   Ainsdale\n",
       "...           ...        ...\n",
       "63532  2022-08-14  Yaverland\n",
       "63537  2022-08-19  Yaverland\n",
       "63546  2022-08-29  Yaverland\n",
       "63565  2022-09-18  Yaverland\n",
       "63575  2022-09-28  Yaverland\n",
       "\n",
       "[14210 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_site_pairs_train = time_site_pairs[~time_site_pairs.isin(time_site_pairs_test)].dropna()\n",
    "time_site_pairs_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Models \n",
    "- Train on training time-site pairs\n",
    "- Test on testing time-site pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################baseline############################\n",
    "train_data = df.merge(time_site_pairs_train, on=['time', 'site'], how='inner')\n",
    "test_data = df.merge(time_site_pairs_train, on=['time', 'site'], how='inner')\n",
    "\n",
    "# Calculate the ratio of the labels in the training set\n",
    "label_ratio_train = train_data['riskLevelLabel'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "# Generate random predictions for the test set with the label ratio from the training set\n",
    "num_test_samples = len(test_data)\n",
    "random_predictions_test = np.random.choice(list(label_ratio_train.keys()), num_test_samples, p=list(label_ratio_train.values()))\n",
    "\n",
    "# Calculate the accuracy of the random coin flip baseline for the test set\n",
    "accuracy_test = np.mean(random_predictions_test == test_data['riskLevelLabel'])\n",
    "print(f'Accuracy of baseline on test set: {accuracy_test:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "df_train = df.merge(time_site_pairs_train, on=['time', 'site'], how='inner')\n",
    "df_test = df.merge(time_site_pairs_test, on=['time', 'site'], how='inner')\n",
    "\n",
    "df_train.drop(['time', 'site'], axis=1, inplace=True)\n",
    "df_test.drop(['time', 'site'], axis=1, inplace=True)\n",
    "\n",
    "y_train = df_train.pop('riskLevelLabel')\n",
    "y_test = df_test.pop('riskLevelLabel')\n",
    "\n",
    "X_train = df_train\n",
    "X_test = df_test\n",
    "\n",
    "print('Training X Shape:', X_train.shape)\n",
    "print('Training y Shape:', y_train.shape)\n",
    "print('Testing X Shape:', X_test.shape)\n",
    "print('Testing y Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# variable selection using LASSO\n",
    "logreg = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "model = SelectFromModel(logreg, prefit=True)\n",
    "X_train_selected = model.transform(X_train_scaled)\n",
    "X_test_selected = model.transform(X_test_scaled)\n",
    "\n",
    "logreg_selected = LogisticRegression(max_iter=10000)\n",
    "logreg_selected.fit(X_train_selected, y_train)\n",
    "y_pred = logreg_selected.predict(X_test_selected)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lg_model(x,y):\n",
    "    lg_model = LogisticRegression(\n",
    "        random_state = 100, #specify the random_state \n",
    "        solver = 'saga',\n",
    "        n_jobs = -1 ,#use all cpu cores\n",
    "        max_iter = 10000 #give more iteration for model to converge \n",
    "    )\n",
    "\n",
    "    params = {'penalty': ['l1', 'l2'],# penalty term\n",
    "              'C': (0.1, 1,10)} #Î» \n",
    "\n",
    "    lg = GridSearchCV(lg_model, params, cv=5,scoring=make_scorer(f1_score, average='macro'))\n",
    "    lg.fit(x, y)\n",
    "    print(lg.best_score_)\n",
    "    print('Best_parameters:',lg.best_params_)\n",
    "    return lg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "base_lg = lg_model(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "def draw_roc(model,X_test,y_test):\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling - based on training data\n",
    "mean_train = X_train.mean() #compute the mean of training set\n",
    "train_std = X_train.std() #compute the std of training set\n",
    "scaled_X_train = (X_train-mean_train)/train_std\n",
    "scaled_X_test = (X_test-mean_train)/train_std # to avoid bias, use the mean and std from training dataset and apply it on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(base_lg, scaled_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_cross_validation_score(model,x,y):\n",
    "    accuray_scores = cross_val_score(model,x, y, scoring='accuracy', cv=5, n_jobs=-1)# evaluate the model through 5 fold cross-validation\n",
    "    auc_scores = cross_val_score(model,x, y, scoring='roc_auc', cv=5, n_jobs=-1)# evaluate the model through 5 fold cross-validation\n",
    "    f1_scores = cross_val_score(model,x, y, scoring='f1', cv=5, n_jobs=-1)# evaluate the model through 5 fold cross-validation\n",
    "    print(str(model),'\\naccuracy:',accuray_scores, '\\naverage accuray:',accuray_scores.mean())\n",
    "    print('\\nauc score:', auc_scores,'\\naverage auc score:',auc_scores.mean())\n",
    "    print('\\nf1 score:',f1_scores,'\\naverage f1 score:',f1_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "training_cross_validation_score(base_lg, X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation(model,x,y):\n",
    "    y_pred = model.predict(x)\n",
    "    print(str(model),\"\\nOn test data,f1 score: %.2f \"%f1_score(y, y_pred))\n",
    "    print(\"On test data,Precision: %.2f\" %precision_score(y, y_pred))\n",
    "    print(\"Recall: %.2f\" %recall_score(y, y_pred))\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy: {:.2f} %\".format(acc*100))\n",
    "    ConfusionMatrixDisplay.from_estimator(model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluation(base_lg, scaled_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "df_train = df_merged.merge(time_site_pairs_train, on=['time', 'site'], how='inner')\n",
    "df_test = df_merged.merge(time_site_pairs_test, on=['time', 'site'], how='inner')\n",
    "\n",
    "df_train.drop(['time', 'site'], axis=1, inplace=True)\n",
    "df_test.drop(['time', 'site'], axis=1, inplace=True)\n",
    "\n",
    "y_train = df_train.pop('riskLevelLabel')\n",
    "y_test = df_test.pop('riskLevelLabel')\n",
    "\n",
    "X_train = df_train\n",
    "X_test = df_test\n",
    "\n",
    "\n",
    "print('Training X Shape:', X_train.shape)\n",
    "print('Training y Shape:', y_train.shape)\n",
    "print('Testing X Shape:', X_test.shape)\n",
    "print('Testing y Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a random forest to the data\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# evaluate the performance\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict well with the 'normal' risk level but not with the 'increased'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of Feature Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dict = dict(zip(df_train.columns, rf.feature_importances_))\n",
    "\n",
    "features = ['11x11', '9x9', '7x7', '5x5', '3x3', '1x1', 'TUR', 'SPM', 'CHL']\n",
    "\n",
    "data = []\n",
    "for s in features:\n",
    "    sum_importance = np.sum([importance for feature, importance in importance_dict.items() if s in feature])\n",
    "    data.append([s, sum_importance])\n",
    "\n",
    "# Create a DataFrame with the calculated data\n",
    "df_importances = pd.DataFrame(data, columns=['Feature', 'Sum of Importances'])\n",
    "\n",
    "def highlight_max(s):\n",
    "    if len(s) > 3:\n",
    "        return ['background-color: #DEB887' if v in list(s[np.argsort(s)[-3:]]) else '' for v in s]\n",
    "    else:\n",
    "        return ['background-color: #8FBC8F' if v == s.max() else '' for v in s]\n",
    "\n",
    "df_importances[:6].style.apply(highlight_max, subset=['Sum of Importances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importances[-3:].style.apply(highlight_max, subset=['Sum of Importances'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test = PCA(n_components=72)\n",
    "pca_test.fit(X_train)\n",
    "sns.set(style='whitegrid')\n",
    "plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.axvline(linewidth=4, color='r', linestyle = '--', x=5, ymin=0, ymax=1)\n",
    "display(plt.show())\n",
    "evr = pca_test.explained_variance_ratio_\n",
    "cvr = np.cumsum(pca_test.explained_variance_ratio_)\n",
    "pca_df = pd.DataFrame()\n",
    "pca_df['Cumulative Variance Ratio'] = cvr\n",
    "pca_df['Explained Variance Ratio'] = evr\n",
    "display(pca_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dims = []\n",
    "for x in range(0, len(pca_df)):\n",
    "    pca_dims.append('PCA Component {}'.format(x))\n",
    "pca_test_df = pd.DataFrame(pca_test.components_, columns=df_train.columns, index=pca_dims)\n",
    "pca_test_df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a random forest to the data\n",
    "rf_pca = RandomForestClassifier()\n",
    "rf_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred_pca = rf_pca.predict(X_test_pca)\n",
    "\n",
    "# evaluate the performance\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred_pca)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_val_nn(input_data, train_labels, test_labels, dim = 11, oversampling = False, desired_pos_ratio =  0.5, train_val_ratio = 0.8):\n",
    "    '''\n",
    "    Gets train, test and validation datasets for a neural network model. \n",
    "    \n",
    "    input: \n",
    "        - input_data (pd.DataFrame): \n",
    "            - dataframe of shape (m, n)\n",
    "            - number of datapoints = m\n",
    "            - features to consider = n-1\n",
    "            - one of the columns = 'riskLevelLabel'\n",
    "            \n",
    "        - train_labels / test_labels (pd.DataFrame):\n",
    "            - dataframe with two columns 'time' and 'site'\n",
    "            - time and site pairs for train/test data\n",
    "        \n",
    "        - oversampling (boolean):\n",
    "            - Whether oversampling should be performed\n",
    "\n",
    "        - desired_pos_ratio (float):\n",
    "            - desired ratio of positive samples when performing random oversampling\n",
    "\n",
    "        - train_val_ratio (float):\n",
    "            - ratio of training data to validation data\n",
    "            \n",
    "    output:\n",
    "        - X_train (tensor)\n",
    "        - X_test (tensor)\n",
    "        - X_val (tensor)\n",
    "        - y_train (np.array)\n",
    "        - y_test (np.array)\n",
    "        - y_val (np.array)\n",
    "    '''\n",
    "    train = pd.merge(train_labels, input_data, on=['time', 'site'])\n",
    "    test = pd.merge(test_labels, input_data, on=['time', 'site'])\n",
    "    \n",
    "    # Changing window size\n",
    "    i = int((dim-1)/2)\n",
    "    \n",
    "    def get_windowed_data(row):\n",
    "        indices = np.array(range(1,122)).reshape(11,11)[5-i:6+i, 5-i:6+i].flatten()\n",
    "        indices = [i-1 for i in indices]\n",
    "        values = row.flatten()[[indices]].reshape(dim,dim)\n",
    "        return values\n",
    "    \n",
    "\n",
    "    if dim != 11:\n",
    "        train['CHL'] = train['CHL'].apply(get_windowed_data)\n",
    "        train['TUR'] = train['TUR'].apply(get_windowed_data)\n",
    "        train['SPM'] = train['SPM'].apply(get_windowed_data)\n",
    "        test['CHL'] = test['CHL'].apply(get_windowed_data)\n",
    "        test['TUR'] = test['TUR'].apply(get_windowed_data)\n",
    "        test['SPM'] = test['SPM'].apply(get_windowed_data)\n",
    "        \n",
    "    # Getting X and y\n",
    "    features_column_names = list(input_data.columns)\n",
    "    for x in ['riskLevelLabel', 'time', 'site']:\n",
    "        features_column_names.remove(x)\n",
    "        \n",
    "    X_train, X_test = train[features_column_names], test[features_column_names]\n",
    "    y_train = np.array([1 if x == 'increased' else 0 for x in train['riskLevelLabel']])\n",
    "    y_test = np.array([1 if x == 'increased' else 0 for x in test['riskLevelLabel']])\n",
    "    \n",
    "    # Oversampling for training data\n",
    "    if oversampling:\n",
    "        \n",
    "        # Counting number of samples to oversample\n",
    "        num_positives, num_negatives = sum(y_train), len(y_train)-sum(y_train)\n",
    "        num_positives_to_repeat = int(desired_pos_ratio * num_negatives * 2) - num_positives\n",
    "        \n",
    "        # Oversampling\n",
    "        ros = RandomOverSampler(sampling_strategy={1: num_positives_to_repeat}, random_state=42)\n",
    "        X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "        \n",
    "    # Reshape and Convert to Tensor\n",
    "    # X_train\n",
    "    if X_train.shape[1] == 1: \n",
    "        X_train = np.array([i for i in X_train[features_column_names[0]]])\n",
    "        X_train = tf.convert_to_tensor(X_train)\n",
    "        X_train = tf.expand_dims(X_train, axis=3, name=None)\n",
    "    else:\n",
    "        X_train = np.stack([np.stack(X_train[col].values) for col in X_train.columns], axis=1)\n",
    "        X_train = np.transpose(X_train, (0, 2, 3, 1))\n",
    "        X_train = tf.convert_to_tensor(X_train)\n",
    "        \n",
    "    # X_test\n",
    "    if X_test.shape[1] == 1: \n",
    "        X_test = np.array([i for i in X_test[features_column_names[0]]])\n",
    "        X_test = tf.convert_to_tensor(X_test)\n",
    "        X_test = tf.expand_dims(X_test, axis=3, name=None)\n",
    "    else:\n",
    "        X_test = np.stack([np.stack(X_test[col].values) for col in X_test.columns], axis=1)\n",
    "        X_test = np.transpose(X_test, (0, 2, 3, 1))\n",
    "        X_test = tf.convert_to_tensor(X_test)\n",
    "        \n",
    "    X_train = tf.pad(X_train, [[0, 0], [16-i,15-i], [16-i,15-i], [0,0]])\n",
    "    X_test = tf.pad(X_test, [[0, 0], [16-i,15-i], [16-i,15-i], [0,0]])\n",
    "    \n",
    "    # Train Validation Split\n",
    "    i = int(X_train.shape[0] * train_val_ratio)\n",
    "    X_val, y_val = X_train[i:], y_train[i:]\n",
    "    X_train, y_train = X_train[:i], y_train[:i]\n",
    "    \n",
    "    return {'X_train': X_train, \n",
    "            'X_test': X_test, \n",
    "            'X_val': X_val, \n",
    "            'y_train': y_train, \n",
    "            'y_test': y_test,\n",
    "            'y_val': y_val}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    f1 score function for Keras\n",
    "    '''\n",
    "    \n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "\n",
    "\n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nn(xy_data, model_type, metrics=['acc','AUC','Precision','Recall', f1], \n",
    "           loss='binary_crossentropy', optimizer='adam',\n",
    "          batch_size=64, epochs=40):\n",
    "    '''\n",
    "    Fits a neural network model and returns history & evaluation metrics on test data.\n",
    "    \n",
    "    input:\n",
    "        - xy_data: dictionary with X_train, X_test, X_val, y_train, y_test, y_val in this order (dict)\n",
    "        - model_type: \"baseline\"/\"convolution\" (string)\n",
    "        - loss: \"binary_crossentropy\" (string)\n",
    "        - metrics: list of metrics to track. available metrics are: (list of string/function)\n",
    "            - \"acc\"\n",
    "            - \"AUC\"\n",
    "            - \"Precision\"\n",
    "            - \"Recall\"\n",
    "            - f1\n",
    "    '''\n",
    "    # unpacking data\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val = xy_data.values()\n",
    "    \n",
    "    # building model\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    if model_type == \"baseline\":\n",
    "        model.add(layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "        model.add(layers.Dense(100, activation='relu'))\n",
    "        model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "    elif model_type == \"convolution\":\n",
    "        model.add(layers.Conv2D(filters=6, kernel_size=5, activation='relu', padding='same', input_shape=X_train.shape[1:]))\n",
    "        model.add(layers.AveragePooling2D(pool_size=2, strides=2))\n",
    "        model.add(layers.Conv2D(filters=16, kernel_size=5, activation='relu'))\n",
    "        model.add(layers.AveragePooling2D(pool_size=2, strides=2))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(120, activation='relu')),\n",
    "        model.add(layers.Dense(84, activation='relu')),\n",
    "        model.add(layers.Dense(10, activation='relu')),\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    else:\n",
    "        print('Model Type Undefined')\n",
    "        \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    \n",
    "    # Fit Model\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), verbose=0)\n",
    "    \n",
    "    # Evaluate Model\n",
    "    result = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return history, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_loss(his, graph_title, ax):\n",
    "    '''\n",
    "    input:\n",
    "        - history (keras.callbacks.History)\n",
    "        - graph_title (string)\n",
    "        - ax: plot location (tuple)\n",
    "    output: 1 graph of train and validation loss across epochs\n",
    "    '''\n",
    "    axs[ax[0], ax[1]].plot(his.history['loss'])\n",
    "    axs[ax[0], ax[1]].plot(his.history['val_loss'])\n",
    "    axs[ax[0], ax[1]].title.set_text(f'{graph_title}')\n",
    "    axs[ax[0], ax[1]].legend(['Training', 'Validation'])\n",
    "\n",
    "def plot_train_val_metric(his, graph_title, ax, metric):\n",
    "    '''\n",
    "    input:\n",
    "        - history (keras.callbacks.History)\n",
    "        - graph_title (string)\n",
    "        - ax: plot location (tuple)\n",
    "        - metric: metric of interest (string)\n",
    "    output: 1 graph of train and validation metric across epochs\n",
    "    '''\n",
    "    axs[ax[0], ax[1]].plot(his.history[f'{metric}'])\n",
    "    axs[ax[0], ax[1]].plot(his.history[f'val_{metric}'])\n",
    "    axs[ax[0], ax[1]].title.set_text(f'{graph_title}')\n",
    "    axs[ax[0], ax[1]].legend(['Training', 'Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-11 18:57:09.131502\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "results = []\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 6/6\n",
      "2023-05-11 19:15:28.674704\n",
      "CPU times: user 33min 52s, sys: 3min 34s, total: 37min 26s\n",
      "Wall time: 7min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "j = 0\n",
    "for dim in [1,3,5,7,9,11]:\n",
    "    \n",
    "    # Getting Input Data\n",
    "    input_data_ = input_data[['CHL', 'SPM', 'TUR', 'riskLevelLabel', 'site', 'time']]\n",
    "        \n",
    "    \n",
    "    # Getting xy_data\n",
    "    xy_data = get_train_test_val_nn(input_data_, \n",
    "                           time_site_pairs_train, \n",
    "                           time_site_pairs_test, \n",
    "                           dim=dim)\n",
    "    \n",
    "    # Get history and result\n",
    "    history, result = fit_nn(xy_data, \"convolution\")\n",
    "    histories.append(history)\n",
    "    results.append(result)\n",
    "    \n",
    "    j += 1\n",
    "    clear_output(wait=True)\n",
    "    print(f'Progress: {j}/6')\n",
    "    print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.015015012584626675,\n",
       " 0.033633626997470856,\n",
       " 0.048648640513420105,\n",
       " 0.039639633148908615]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ = results[:-6]\n",
    "f1_scores = [i[5] for i in results_]\n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28fc86620>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1,3,5,7,9,11], f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 3), dtype=float64, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_ = input_data[['CHL', 'SPM', 'TUR', 'riskLevelLabel', 'site', 'time']]\n",
    "\n",
    "xy_data = get_train_test_val_nn(input_data_, \n",
    "                           time_site_pairs_train, \n",
    "                           time_site_pairs_test, \n",
    "                           oversampling = True)\n",
    "xy_data['X_train'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 3), dtype=float64, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_ = input_data[['CHL', 'SPM', 'TUR', 'riskLevelLabel', 'site', 'time']]\n",
    "\n",
    "train = pd.merge(time_site_pairs_train, input_data, on=['time', 'site'])\n",
    "\n",
    "dim = 11\n",
    "\n",
    "i = int((dim-1)/2)\n",
    "def get_windowed_data(row):\n",
    "    indices = np.array(range(1,122)).reshape(11,11)[5-i:6+i, 5-i:6+i].flatten()\n",
    "    indices = [i-1 for i in indices]\n",
    "    values = row.flatten()[[indices]].reshape(dim,dim)\n",
    "    return values\n",
    "\n",
    "train['CHL'] = train['CHL'].apply(get_windowed_data)\n",
    "train['SPM'] = train['SPM'].apply(get_windowed_data)\n",
    "train['TUR'] = train['TUR'].apply(get_windowed_data)\n",
    "\n",
    "X_train = train[['CHL', 'TUR', 'SPM']]\n",
    "# train['CHL'][0].flatten()[[indices]]\n",
    "\n",
    "X_train = np.stack([np.stack(X_train[col].values) for col in X_train.columns], axis=1)\n",
    "X_train = np.transpose(X_train, (0, 2, 3, 1))\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "\n",
    "\n",
    "X_train = tf.pad(X_train, [[0, 0], [16-i,15-i], [16-i,15-i], [0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get results for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-11 18:08:39.283888\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "results = []\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "\n",
    "model_types = [\"baseline\", \"convolution\"]\n",
    "num_features = [1,3]\n",
    "oversampling_ = [True, False]\n",
    "i = 0\n",
    "\n",
    "for model_type, num_feature, oversampling__ in itertools.product(model_types, num_features, oversampling_):\n",
    "    \n",
    "    # Getting Input Data\n",
    "    if num_feature == 1:\n",
    "        input_data_ = input_data[['CHL', 'riskLevelLabel', 'site', 'time']]\n",
    "        \n",
    "    elif num_feature == 3:\n",
    "        input_data_ = input_data[['CHL', 'SPM', 'TUR', 'riskLevelLabel', 'site', 'time']]\n",
    "        \n",
    "    \n",
    "    # Getting xy_data\n",
    "    xy_data = get_train_test_val_nn(input_data_, \n",
    "                           time_site_pairs_train, \n",
    "                           time_site_pairs_test, \n",
    "                           oversampling = oversampling_)\n",
    "    \n",
    "    # Get history and result\n",
    "    history, result = fit_nn(xy_data, model_type)\n",
    "    histories.append(history)\n",
    "    results.append(result)\n",
    "    \n",
    "    i += 1\n",
    "    clear_output(wait=True)\n",
    "    print(f'Progress: {i}/{len(model_types)*len(num_features)*len(oversampling_)}')\n",
    "    print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "\n",
    "for model_type, num_feature, oversampling__ in itertools.product(model_types, num_features, oversampling_):\n",
    "    oversample = \"Oversampling\" if oversampling__ else \"No Oversampling\"\n",
    "    model_names.append(f'{model_type.capitalize()}, {num_feature} feature, {oversample}')\n",
    "    \n",
    "df1 = pd.DataFrame(model_names, columns=['Sub-Model'])\n",
    "df2 = pd.DataFrame(results, columns=['loss', 'acc','AUC','Precision','Recall', 'f1'])\n",
    "results_df_nn = pd.concat([df1, df2], axis=1)\n",
    "results_df_nn['Model'] = ['Neural Network']*8\n",
    "results_df_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_string = model_names\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, ncols=2, figsize=(10, 12), sharex=True, sharey=True)\n",
    "\n",
    "for j in range(8):\n",
    "    ax = ([(k,i) for k in range(4) for i in range(2)])[j]\n",
    "    plot_train_val_loss(histories[j], model_names_string[j], ax)\n",
    "\n",
    "plt.suptitle('Training Loss vs Validation Loss')\n",
    "fig.supxlabel(\"Epochs\")\n",
    "fig.supylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric='f1'\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, ncols=2, figsize=(10, 12), sharex=True, sharey=True)\n",
    "\n",
    "for j in range(8):\n",
    "    ax = ([(k,i) for k in range(4) for i in range(2)])[j]\n",
    "    plot_train_val_metric(histories[j], model_names_string[j], ax, metric=metric)\n",
    "\n",
    "plt.suptitle(f'Training {metric} vs Validation {metric}')\n",
    "fig.supxlabel(\"Epochs\")\n",
    "fig.supylabel(f\"{metric}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results\n",
    "Dummy / sketch dataframe (just as an example, sub-models and statistics tbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_nn_final = results_df_nn[['Model', 'Sub-Model', 'AUC','Precision','Recall','f1','acc']]\n",
    "results_df_nn_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [('Baseline Random Guess', 'N/A'),\n",
    "        ('BC', 'No oversampling, all features'),\n",
    "         ('BC', 'No oversampling, top 10 features'),\n",
    "         ('BC', 'Oversampling, all features'),\n",
    "         ('BC', 'Oversampling, top 10 features'),\n",
    "         ('RF', 'No oversampling'),\n",
    "         ('RF', 'Oversampling'),\n",
    "         ('NN', 'No oversampling'),\n",
    "         ('NN', 'Oversampling')]\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=[\"Model\", \"Sub-Model\"])\n",
    "\n",
    "df = pd.DataFrame(columns = {'F1': [0,0,0,0,0,0,0,0,0], \n",
    "                            'Precision': [0,0,0,0,0,0,0,0,0],\n",
    "                            'Recall': [0,0,0,0,0,0,0,0,0],\n",
    "                            'AUC': [0,0,0,0,0,0,0,0,0], \n",
    "                            'Acc': [0,0,0,0,0,0,0,0,0]}, index = index)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window Size against F1 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change tensor size: 1x1, 3x3, 5x5, 7x7, 9x9, 11x11\n",
    "# run best NN model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv-kernel",
   "language": "python",
   "name": "local-venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
