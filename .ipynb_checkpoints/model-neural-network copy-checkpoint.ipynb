{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Satellite Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>TUR</th>\n",
       "      <th>SPM</th>\n",
       "      <th>CHL</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>55.189352</td>\n",
       "      <td>-1.519043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newbiggin_North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>55.189352</td>\n",
       "      <td>-1.517296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newbiggin_North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>55.189352</td>\n",
       "      <td>-1.515549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newbiggin_North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>55.189352</td>\n",
       "      <td>-1.513802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newbiggin_North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>55.189352</td>\n",
       "      <td>-1.512055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newbiggin_North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331105</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>50.277315</td>\n",
       "      <td>-3.893256</td>\n",
       "      <td>2.006134</td>\n",
       "      <td>1.186131</td>\n",
       "      <td>1.828091</td>\n",
       "      <td>Bigbury-on-Sea_South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331106</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>50.277315</td>\n",
       "      <td>-3.891509</td>\n",
       "      <td>0.708182</td>\n",
       "      <td>0.406647</td>\n",
       "      <td>1.046769</td>\n",
       "      <td>Bigbury-on-Sea_South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331107</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>50.277315</td>\n",
       "      <td>-3.889762</td>\n",
       "      <td>1.258156</td>\n",
       "      <td>0.729469</td>\n",
       "      <td>1.327342</td>\n",
       "      <td>Bigbury-on-Sea_South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331108</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>50.277315</td>\n",
       "      <td>-3.888015</td>\n",
       "      <td>1.037095</td>\n",
       "      <td>0.598882</td>\n",
       "      <td>1.254974</td>\n",
       "      <td>Bigbury-on-Sea_South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331109</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>50.277315</td>\n",
       "      <td>-3.886268</td>\n",
       "      <td>0.563590</td>\n",
       "      <td>0.323039</td>\n",
       "      <td>1.018072</td>\n",
       "      <td>Bigbury-on-Sea_South</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12331110 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                time        lat       lon       TUR       SPM       CHL  \\\n",
       "0         2022-03-01  55.189352 -1.519043       NaN       NaN       NaN   \n",
       "1         2022-03-01  55.189352 -1.517296       NaN       NaN       NaN   \n",
       "2         2022-03-01  55.189352 -1.515549       NaN       NaN       NaN   \n",
       "3         2022-03-01  55.189352 -1.513802       NaN       NaN       NaN   \n",
       "4         2022-03-01  55.189352 -1.512055       NaN       NaN       NaN   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "12331105  2022-10-31  50.277315 -3.893256  2.006134  1.186131  1.828091   \n",
       "12331106  2022-10-31  50.277315 -3.891509  0.708182  0.406647  1.046769   \n",
       "12331107  2022-10-31  50.277315 -3.889762  1.258156  0.729469  1.327342   \n",
       "12331108  2022-10-31  50.277315 -3.888015  1.037095  0.598882  1.254974   \n",
       "12331109  2022-10-31  50.277315 -3.886268  0.563590  0.323039  1.018072   \n",
       "\n",
       "                          site  \n",
       "0              Newbiggin_North  \n",
       "1              Newbiggin_North  \n",
       "2              Newbiggin_North  \n",
       "3              Newbiggin_North  \n",
       "4              Newbiggin_North  \n",
       "...                        ...  \n",
       "12331105  Bigbury-on-Sea_South  \n",
       "12331106  Bigbury-on-Sea_South  \n",
       "12331107  Bigbury-on-Sea_South  \n",
       "12331108  Bigbury-on-Sea_South  \n",
       "12331109  Bigbury-on-Sea_South  \n",
       "\n",
       "[12331110 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_data = pd.read_csv(\"~data/sites_data_11x11.csv\")\n",
    "sites_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time           0\n",
       "lat            0\n",
       "lon            0\n",
       "TUR     10838900\n",
       "SPM     10838900\n",
       "CHL     10838900\n",
       "site           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Null Values with 0\n",
    "\n",
    "sites_data.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pollution Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>site</th>\n",
       "      <th>time</th>\n",
       "      <th>warning</th>\n",
       "      <th>riskLevelLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Seaton Carew North</td>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>Pollution RIsk Forecasts will start soon</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Seaton Carew North</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>Pollution RIsk Forecasts will start soon</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Seaton Carew North</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Pollution RIsk Forecasts will start soon</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Seaton Carew North</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>No warnings in place</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Seaton Carew North</td>\n",
       "      <td>2022-05-05</td>\n",
       "      <td>No warnings in place</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63641</th>\n",
       "      <td>63641</td>\n",
       "      <td>Westward Ho!</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63642</th>\n",
       "      <td>63642</td>\n",
       "      <td>Westward Ho!</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63643</th>\n",
       "      <td>63643</td>\n",
       "      <td>Westward Ho!</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63644</th>\n",
       "      <td>63644</td>\n",
       "      <td>Westward Ho!</td>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63645</th>\n",
       "      <td>63645</td>\n",
       "      <td>Westward Ho!</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>No pollution incidents reported</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63646 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                site        time  \\\n",
       "0               0  Seaton Carew North  2022-04-28   \n",
       "1               1  Seaton Carew North  2022-04-29   \n",
       "2               2  Seaton Carew North  2022-04-30   \n",
       "3               3  Seaton Carew North  2022-05-04   \n",
       "4               4  Seaton Carew North  2022-05-05   \n",
       "...           ...                 ...         ...   \n",
       "63641       63641        Westward Ho!  2022-09-26   \n",
       "63642       63642        Westward Ho!  2022-09-27   \n",
       "63643       63643        Westward Ho!  2022-09-28   \n",
       "63644       63644        Westward Ho!  2022-09-29   \n",
       "63645       63645        Westward Ho!  2022-09-30   \n",
       "\n",
       "                                        warning riskLevelLabel  \n",
       "0      Pollution RIsk Forecasts will start soon         normal  \n",
       "1      Pollution RIsk Forecasts will start soon         normal  \n",
       "2      Pollution RIsk Forecasts will start soon         normal  \n",
       "3                          No warnings in place         normal  \n",
       "4                          No warnings in place         normal  \n",
       "...                                         ...            ...  \n",
       "63641           No pollution incidents reported         normal  \n",
       "63642           No pollution incidents reported         normal  \n",
       "63643           No pollution incidents reported         normal  \n",
       "63644           No pollution incidents reported         normal  \n",
       "63645           No pollution incidents reported         normal  \n",
       "\n",
       "[63646 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "riskforecasting = pd.read_csv('~data/pollution_risk_forecasting.csv')\n",
    "riskforecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Datasets to Create Input Dataset\n",
    "For every site (430) and time (237), create a 11 x 11 x 3 tensor, each corresponding to one risk level label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.83 s, sys: 925 ms, total: 6.75 s\n",
      "Wall time: 7.29 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TUR</th>\n",
       "      <th>SPM</th>\n",
       "      <th>CHL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022-03-01</th>\n",
       "      <th>Ainsdale</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allonby</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allonby_South</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amble_Links</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anderby</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022-10-31</th>\n",
       "      <th>Withernsea</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wolvercote_Mill_Stream</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Woolacombe_Village</th>\n",
       "      <td>[[5.9864016, 25.982555, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[[3.564524, 16.43204, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[6.564089, 6.803925, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Worthing</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yaverland</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101910 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 TUR  \\\n",
       "time       site                                                                        \n",
       "2022-03-01 Ainsdale                [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Allonby                 [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Allonby_South           [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Amble_Links             [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Anderby                 [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "...                                                                              ...   \n",
       "2022-10-31 Withernsea              [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Wolvercote_Mill_Stream  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Woolacombe_Village      [[5.9864016, 25.982555, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "           Worthing                [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Yaverland               [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                                                                 SPM  \\\n",
       "time       site                                                                        \n",
       "2022-03-01 Ainsdale                [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Allonby                 [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Allonby_South           [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Amble_Links             [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Anderby                 [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "...                                                                              ...   \n",
       "2022-10-31 Withernsea              [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Wolvercote_Mill_Stream  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Woolacombe_Village      [[3.564524, 16.43204, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Worthing                [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "           Yaverland               [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                                                                 CHL  \n",
       "time       site                                                                       \n",
       "2022-03-01 Ainsdale                [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "           Allonby                 [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "           Allonby_South           [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "           Amble_Links             [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "           Anderby                 [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "...                                                                              ...  \n",
       "2022-10-31 Withernsea              [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "           Wolvercote_Mill_Stream  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "           Woolacombe_Village      [[6.564089, 6.803925, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "           Worthing                [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "           Yaverland               [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "\n",
       "[101910 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def chl_to_array(chl_values):\n",
    "    # Not 100% sure if this reshapes according to lat/lon (though it does not matter if we perform the same operation every time?)\n",
    "    return np.array(chl_values).reshape(11, 11)\n",
    "\n",
    "def get_features_data(sites_data, features_list):\n",
    "    '''\n",
    "    input: \n",
    "        - sites_data (pd.DataFrame):\n",
    "            - dataframe where each row contains feature values for a time, site and coordinate\n",
    "        - features_list (list):\n",
    "            - list of strings of features to use\n",
    "            \n",
    "    output:\n",
    "        - features data (pd.DataFrame)\n",
    "            - row: data for every time and site pair\n",
    "            - column: features\n",
    "            - entries: np.array of shape 11x11\n",
    "    '''\n",
    "    dfs = []\n",
    "    for feature in features_list:\n",
    "        df = pd.DataFrame(sites_data.groupby(['time', 'site'])[feature].apply(chl_to_array))\n",
    "        dfs.append(df)\n",
    "    input_data = reduce(lambda  left,right: pd.merge(left,right,on=['time', 'site'],how='outer'), dfs)\n",
    "    \n",
    "    return input_data\n",
    "\n",
    "features_df = get_features_data(sites_data, ['TUR', 'SPM', 'CHL'])\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>site</th>\n",
       "      <th>time</th>\n",
       "      <th>riskLevelLabel</th>\n",
       "      <th>Site Name in Files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Seaton Carew North</td>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>normal</td>\n",
       "      <td>Seaton_Carew_North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Seaton Carew North</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>normal</td>\n",
       "      <td>Seaton_Carew_North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Seaton Carew North</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>normal</td>\n",
       "      <td>Seaton_Carew_North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Seaton Carew North</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>normal</td>\n",
       "      <td>Seaton_Carew_North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Seaton Carew North</td>\n",
       "      <td>2022-05-05</td>\n",
       "      <td>normal</td>\n",
       "      <td>Seaton_Carew_North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63641</th>\n",
       "      <td>63641</td>\n",
       "      <td>Westward Ho!</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>normal</td>\n",
       "      <td>Westward_Ho!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63642</th>\n",
       "      <td>63642</td>\n",
       "      <td>Westward Ho!</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>normal</td>\n",
       "      <td>Westward_Ho!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63643</th>\n",
       "      <td>63643</td>\n",
       "      <td>Westward Ho!</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>normal</td>\n",
       "      <td>Westward_Ho!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63644</th>\n",
       "      <td>63644</td>\n",
       "      <td>Westward Ho!</td>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>normal</td>\n",
       "      <td>Westward_Ho!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63645</th>\n",
       "      <td>63645</td>\n",
       "      <td>Westward Ho!</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>normal</td>\n",
       "      <td>Westward_Ho!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63646 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                site        time riskLevelLabel  \\\n",
       "0               0  Seaton Carew North  2022-04-28         normal   \n",
       "1               1  Seaton Carew North  2022-04-29         normal   \n",
       "2               2  Seaton Carew North  2022-04-30         normal   \n",
       "3               3  Seaton Carew North  2022-05-04         normal   \n",
       "4               4  Seaton Carew North  2022-05-05         normal   \n",
       "...           ...                 ...         ...            ...   \n",
       "63641       63641        Westward Ho!  2022-09-26         normal   \n",
       "63642       63642        Westward Ho!  2022-09-27         normal   \n",
       "63643       63643        Westward Ho!  2022-09-28         normal   \n",
       "63644       63644        Westward Ho!  2022-09-29         normal   \n",
       "63645       63645        Westward Ho!  2022-09-30         normal   \n",
       "\n",
       "       Site Name in Files  \n",
       "0      Seaton_Carew_North  \n",
       "1      Seaton_Carew_North  \n",
       "2      Seaton_Carew_North  \n",
       "3      Seaton_Carew_North  \n",
       "4      Seaton_Carew_North  \n",
       "...                   ...  \n",
       "63641        Westward_Ho!  \n",
       "63642        Westward_Ho!  \n",
       "63643        Westward_Ho!  \n",
       "63644        Westward_Ho!  \n",
       "63645        Westward_Ho!  \n",
       "\n",
       "[63646 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naming inconsistencies\n",
    "\n",
    "site_df = pd.read_csv(\"~data/site.csv\")\n",
    "site_df = site_df[['label', 'Site Name in Files']]\n",
    "riskforecasting = riskforecasting.merge(site_df, left_on='site', right_on='label', how='left').drop(['label', 'warning'], axis=1)\n",
    "riskforecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging datasets. Merge on riskforecasting (only add CHL values if we have a risklevellabel)\n",
    "input_data = features_df.merge(riskforecasting, how='right', left_on=['time', 'site'], right_on=['time', 'Site Name in Files'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-07-23    421\n",
       "2022-07-25    421\n",
       "2022-02-08      2\n",
       "2022-12-02      2\n",
       "2022-02-25      2\n",
       "2022-02-06      2\n",
       "2022-11-07      1\n",
       "2022-11-08      1\n",
       "2022-11-03      1\n",
       "2022-11-04      1\n",
       "2022-01-09      1\n",
       "2022-12-07      1\n",
       "2022-12-08      1\n",
       "2023-01-17      1\n",
       "2022-12-19      1\n",
       "2022-04-06      1\n",
       "2022-02-09      1\n",
       "2022-02-10      1\n",
       "2022-02-19      1\n",
       "2022-02-23      1\n",
       "2022-01-17      1\n",
       "Name: time, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No satellite data from 07-23 and 07-25\n",
    "\n",
    "input_data[input_data['CHL'].isnull()]['time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>TUR</th>\n",
       "      <th>SPM</th>\n",
       "      <th>CHL</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>site</th>\n",
       "      <th>riskLevelLabel</th>\n",
       "      <th>Site Name in Files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13905</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13905</td>\n",
       "      <td>Ingoldmells South</td>\n",
       "      <td>normal</td>\n",
       "      <td>Ingoldmells_South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21307</th>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21307</td>\n",
       "      <td>Pevensey Bay</td>\n",
       "      <td>increased</td>\n",
       "      <td>Pevensey_Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21308</th>\n",
       "      <td>2022-02-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21308</td>\n",
       "      <td>Pevensey Bay</td>\n",
       "      <td>normal</td>\n",
       "      <td>Pevensey_Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21460</td>\n",
       "      <td>Eastbourne</td>\n",
       "      <td>increased</td>\n",
       "      <td>Eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21461</th>\n",
       "      <td>2022-02-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21461</td>\n",
       "      <td>Eastbourne</td>\n",
       "      <td>normal</td>\n",
       "      <td>Eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27204</th>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27204</td>\n",
       "      <td>Gurnard</td>\n",
       "      <td>increased</td>\n",
       "      <td>Gurnard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27205</th>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27205</td>\n",
       "      <td>Gurnard</td>\n",
       "      <td>normal</td>\n",
       "      <td>Gurnard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27804</th>\n",
       "      <td>2022-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27804</td>\n",
       "      <td>Seagrove</td>\n",
       "      <td>increased</td>\n",
       "      <td>Seagrove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27805</th>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27805</td>\n",
       "      <td>Seagrove</td>\n",
       "      <td>normal</td>\n",
       "      <td>Seagrove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43071</th>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43071</td>\n",
       "      <td>Maenporth</td>\n",
       "      <td>increased</td>\n",
       "      <td>Maenporth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43072</th>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43072</td>\n",
       "      <td>Maenporth</td>\n",
       "      <td>normal</td>\n",
       "      <td>Maenporth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44585</th>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44585</td>\n",
       "      <td>Coverack</td>\n",
       "      <td>increased</td>\n",
       "      <td>Coverack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44586</th>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44586</td>\n",
       "      <td>Coverack</td>\n",
       "      <td>normal</td>\n",
       "      <td>Coverack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44587</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44587</td>\n",
       "      <td>Coverack</td>\n",
       "      <td>increased</td>\n",
       "      <td>Coverack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45043</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45043</td>\n",
       "      <td>Poldhu Cove</td>\n",
       "      <td>increased</td>\n",
       "      <td>Poldhu_Cove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45044</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45044</td>\n",
       "      <td>Poldhu Cove</td>\n",
       "      <td>normal</td>\n",
       "      <td>Poldhu_Cove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47612</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47612</td>\n",
       "      <td>Summerleaze</td>\n",
       "      <td>increased</td>\n",
       "      <td>Summerleaze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54117</th>\n",
       "      <td>2022-02-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54117</td>\n",
       "      <td>Porth</td>\n",
       "      <td>increased</td>\n",
       "      <td>Porth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54118</th>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54118</td>\n",
       "      <td>Porth</td>\n",
       "      <td>normal</td>\n",
       "      <td>Porth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59412</th>\n",
       "      <td>2022-02-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59412</td>\n",
       "      <td>Combe Martin</td>\n",
       "      <td>increased</td>\n",
       "      <td>Combe_Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59413</th>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59413</td>\n",
       "      <td>Combe Martin</td>\n",
       "      <td>normal</td>\n",
       "      <td>Combe_Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60471</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60471</td>\n",
       "      <td>Salcombe North Sands</td>\n",
       "      <td>increased</td>\n",
       "      <td>Salcombe_North_Sands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60624</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60624</td>\n",
       "      <td>Salcombe South Sands</td>\n",
       "      <td>increased</td>\n",
       "      <td>Salcombe_South_Sands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time  TUR  SPM  CHL  Unnamed: 0                  site  \\\n",
       "13905  2022-12-19  NaN  NaN  NaN       13905     Ingoldmells South   \n",
       "21307  2022-02-06  NaN  NaN  NaN       21307          Pevensey Bay   \n",
       "21308  2022-02-08  NaN  NaN  NaN       21308          Pevensey Bay   \n",
       "21460  2022-02-06  NaN  NaN  NaN       21460            Eastbourne   \n",
       "21461  2022-02-08  NaN  NaN  NaN       21461            Eastbourne   \n",
       "27204  2022-11-07  NaN  NaN  NaN       27204               Gurnard   \n",
       "27205  2022-11-08  NaN  NaN  NaN       27205               Gurnard   \n",
       "27804  2022-11-03  NaN  NaN  NaN       27804              Seagrove   \n",
       "27805  2022-11-04  NaN  NaN  NaN       27805              Seagrove   \n",
       "43071  2022-01-09  NaN  NaN  NaN       43071             Maenporth   \n",
       "43072  2022-01-17  NaN  NaN  NaN       43072             Maenporth   \n",
       "44585  2022-12-07  NaN  NaN  NaN       44585              Coverack   \n",
       "44586  2022-12-08  NaN  NaN  NaN       44586              Coverack   \n",
       "44587  2023-01-17  NaN  NaN  NaN       44587              Coverack   \n",
       "45043  2022-12-02  NaN  NaN  NaN       45043           Poldhu Cove   \n",
       "45044  2022-12-02  NaN  NaN  NaN       45044           Poldhu Cove   \n",
       "47612  2022-04-06  NaN  NaN  NaN       47612           Summerleaze   \n",
       "54117  2022-02-09  NaN  NaN  NaN       54117                 Porth   \n",
       "54118  2022-02-10  NaN  NaN  NaN       54118                 Porth   \n",
       "59412  2022-02-19  NaN  NaN  NaN       59412          Combe Martin   \n",
       "59413  2022-02-23  NaN  NaN  NaN       59413          Combe Martin   \n",
       "60471  2022-02-25  NaN  NaN  NaN       60471  Salcombe North Sands   \n",
       "60624  2022-02-25  NaN  NaN  NaN       60624  Salcombe South Sands   \n",
       "\n",
       "      riskLevelLabel    Site Name in Files  \n",
       "13905         normal     Ingoldmells_South  \n",
       "21307      increased          Pevensey_Bay  \n",
       "21308         normal          Pevensey_Bay  \n",
       "21460      increased            Eastbourne  \n",
       "21461         normal            Eastbourne  \n",
       "27204      increased               Gurnard  \n",
       "27205         normal               Gurnard  \n",
       "27804      increased              Seagrove  \n",
       "27805         normal              Seagrove  \n",
       "43071      increased             Maenporth  \n",
       "43072         normal             Maenporth  \n",
       "44585      increased              Coverack  \n",
       "44586         normal              Coverack  \n",
       "44587      increased              Coverack  \n",
       "45043      increased           Poldhu_Cove  \n",
       "45044         normal           Poldhu_Cove  \n",
       "47612      increased           Summerleaze  \n",
       "54117      increased                 Porth  \n",
       "54118         normal                 Porth  \n",
       "59412      increased          Combe_Martin  \n",
       "59413         normal          Combe_Martin  \n",
       "60471      increased  Salcombe_North_Sands  \n",
       "60624      increased  Salcombe_South_Sands  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other missing values to look into - why do we have risk level labels but not satellite data when merging? Naming issue?\n",
    "\n",
    "missing_vals = input_data[(input_data['CHL'].isnull()) & (input_data['time'] != '2022-07-23') & (input_data['time'] != '2022-07-25')]\n",
    "missing_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13905</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>Ingoldmells South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21307</th>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>Pevensey Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21308</th>\n",
       "      <td>2022-02-08</td>\n",
       "      <td>Pevensey Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>Eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21461</th>\n",
       "      <td>2022-02-08</td>\n",
       "      <td>Eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27204</th>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>Gurnard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27205</th>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>Gurnard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27804</th>\n",
       "      <td>2022-11-03</td>\n",
       "      <td>Seagrove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27805</th>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>Seagrove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43071</th>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>Maenporth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43072</th>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>Maenporth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44585</th>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>Coverack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44586</th>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>Coverack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44587</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>Coverack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45043</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>Poldhu Cove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45044</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>Poldhu Cove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47612</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>Summerleaze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54117</th>\n",
       "      <td>2022-02-09</td>\n",
       "      <td>Porth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54118</th>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>Porth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59412</th>\n",
       "      <td>2022-02-19</td>\n",
       "      <td>Combe Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59413</th>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>Combe Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60471</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Salcombe North Sands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60624</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Salcombe South Sands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time                  site\n",
       "13905  2022-12-19     Ingoldmells South\n",
       "21307  2022-02-06          Pevensey Bay\n",
       "21308  2022-02-08          Pevensey Bay\n",
       "21460  2022-02-06            Eastbourne\n",
       "21461  2022-02-08            Eastbourne\n",
       "27204  2022-11-07               Gurnard\n",
       "27205  2022-11-08               Gurnard\n",
       "27804  2022-11-03              Seagrove\n",
       "27805  2022-11-04              Seagrove\n",
       "43071  2022-01-09             Maenporth\n",
       "43072  2022-01-17             Maenporth\n",
       "44585  2022-12-07              Coverack\n",
       "44586  2022-12-08              Coverack\n",
       "44587  2023-01-17              Coverack\n",
       "45043  2022-12-02           Poldhu Cove\n",
       "45044  2022-12-02           Poldhu Cove\n",
       "47612  2022-04-06           Summerleaze\n",
       "54117  2022-02-09                 Porth\n",
       "54118  2022-02-10                 Porth\n",
       "59412  2022-02-19          Combe Martin\n",
       "59413  2022-02-23          Combe Martin\n",
       "60471  2022-02-25  Salcombe North Sands\n",
       "60624  2022-02-25  Salcombe South Sands"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_vals[['time', 'site']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA values for now\n",
    "input_data.dropna(inplace=True)\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where everything is 0 (i.e. all missing values)\n",
    "def has_nonzero(arr):\n",
    "    return np.any(arr != 0)\n",
    "\n",
    "input_data = input_data[input_data['CHL'].apply(has_nonzero)]\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Dataset to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_val(input_data, desired_pos_ratio =  0.5, train_test_ratio = 0.8, train_val_ratio = 0.8):\n",
    "    '''\n",
    "    input: \n",
    "        - input_data (pd.DataFrame): \n",
    "            - dataframe of shape (m, n)\n",
    "            - number of datapoints = m\n",
    "            - features to consider = n-1\n",
    "            - one of the columns = 'riskLevelLabel'\n",
    "\n",
    "        - desired_pos_ratio (float):\n",
    "            - desired ratio of positive samples when performing random oversampling\n",
    "\n",
    "        - train_test_ratio (float):\n",
    "            - ratio of training data to testing data\n",
    "\n",
    "        - train_val_ratio (float):\n",
    "            - ratio of training data to validation data\n",
    "            \n",
    "    output:\n",
    "        - X_train (tensor)\n",
    "        - X_test (tensor)\n",
    "        - X_val (tensor)\n",
    "        - y_train (np.array)\n",
    "        - y_test (np.array)\n",
    "        - y_val (np.array)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Getting X and y\n",
    "    features_column_names = list(input_data.columns)\n",
    "    features_column_names.remove('riskLevelLabel')\n",
    "    X = input_data[features_column_names]\n",
    "    y = np.array([1 if x == 'increased' else 0 for x in input_data['riskLevelLabel']])\n",
    "    \n",
    "    # Counting number of samples to oversample\n",
    "    num_positives, num_negatives = sum(y), len(y)-sum(y)\n",
    "    num_positives_to_repeat = int(desired_pos_ratio * num_negatives * 2) - num_positives\n",
    "    \n",
    "    # Oversampling\n",
    "    ros = RandomOverSampler(sampling_strategy={1: num_positives_to_repeat}, random_state=42)\n",
    "    X, y = ros.fit_resample(X, y)\n",
    "    \n",
    "    # Reshape and Convert to Tensor\n",
    "    if X.shape[1] == 1: \n",
    "        X = np.array([i for i in X[features_column_names[0]]])\n",
    "        X = tf.convert_to_tensor(X)\n",
    "        X = tf.expand_dims(X, axis=3, name=None)\n",
    "    else:\n",
    "        X = np.stack([np.stack(X[col].values) for col in X.columns], axis=1)\n",
    "        X = np.transpose(X, (0, 2, 3, 1))\n",
    "        X = tf.convert_to_tensor(X)\n",
    "    \n",
    "    # Reshape to 32x32 with simple padding for model input\n",
    "    X = tf.pad(X, [[0, 0], [11,10], [11,10], [0,0]])\n",
    "    \n",
    "    # Train Test Split\n",
    "    i = int(X.shape[0] * train_test_ratio)\n",
    "    X_train, y_train = X[:i], y[:i]\n",
    "    X_test, y_test = X[i:], y[i:]\n",
    "\n",
    "    # Train Validation Split\n",
    "    i = int(X.shape[0] * train_test_ratio * train_val_ratio)\n",
    "    X_val, y_val = X_train[i:], y_train[i:]\n",
    "    X_train, y_train = X_train[:i], y_train[:i]\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_data[['CHL']]\n",
    "X.columns[0]\n",
    "# X = np.array([i for i in X])\n",
    "# X = tf.convert_to_tensor(X)\n",
    "# X = tf.expand_dims(X, axis=3, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_data[['CHL']]\n",
    "np.array([i for i in X['CHL']]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline (No Convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = models.Sequential()\n",
    "model_b.add(layers.AveragePooling2D(pool_size=2, strides=2, input_shape=X_train.shape[1:]))\n",
    "model_b.add(layers.Flatten())\n",
    "model_b.add(layers.Dense(120, activation='relu')),\n",
    "model_b.add(layers.Dense(84, activation='relu')),\n",
    "model_b.add(layers.Dense(10, activation='relu')),\n",
    "model_b.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=5, activation='relu', padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(layers.AveragePooling2D(pool_size=2, strides=2))\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=5, activation='relu'))\n",
    "model.add(layers.AveragePooling2D(pool_size=2, strides=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(120, activation='relu')),\n",
    "model.add(layers.Dense(84, activation='relu')),\n",
    "model.add(layers.Dense(10, activation='relu')),\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_loss_acc(his):\n",
    "    '''\n",
    "    input: history\n",
    "    output: 2 graphs\n",
    "    '''\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10,10))\n",
    "    axs[0].plot(his.history['loss'])\n",
    "    axs[0].plot(his.history['val_loss'])\n",
    "    axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "    axs[0].set_xlabel(\"Epochs\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    axs[0].legend(['Training', 'Validation'])\n",
    "    axs[1].plot(his.history['acc'])\n",
    "    axs[1].plot(his.history['val_acc'])\n",
    "    axs[1].title.set_text('Training Acc vs Validation Acc')\n",
    "    axs[1].legend(['Training', 'Validation'])\n",
    "    axs[1].set_xlabel(\"Epochs\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline, 1 feature (CHL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_ = input_data[['CHL', 'riskLevelLabel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = get_train_test_val(input_data_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = models.Sequential()\n",
    "model_b.add(layers.AveragePooling2D(pool_size=2, strides=2, input_shape=X_train.shape[1:]))\n",
    "model_b.add(layers.Flatten())\n",
    "model_b.add(layers.Dense(120, activation='relu')),\n",
    "model_b.add(layers.Dense(84, activation='relu')),\n",
    "model_b.add(layers.Dense(10, activation='relu')),\n",
    "model_b.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_b = model_b.fit(X_train, y_train, batch_size=64, epochs=40, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_loss_acc(history_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_b_1 = model_b.evaluate(X_test, y_test)\n",
    "result_b_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution, 1 feature (CHL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=5, activation='relu', padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(layers.AveragePooling2D(pool_size=2, strides=2))\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=5, activation='relu'))\n",
    "model.add(layers.AveragePooling2D(pool_size=2, strides=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(120, activation='relu')),\n",
    "model.add(layers.Dense(84, activation='relu')),\n",
    "model.add(layers.Dense(10, activation='relu')),\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=40, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_c_1 = model.evaluate(X_test, y_test)\n",
    "result_c_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline, 3 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_ = input_data[['TUR', 'SPM', 'CHL', 'riskLevelLabel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = get_train_test_val(input_data_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_b = models.Sequential()\n",
    "model_b.add(layers.AveragePooling2D(pool_size=2, strides=2, input_shape=X_train.shape[1:]))\n",
    "model_b.add(layers.Flatten())\n",
    "model_b.add(layers.Dense(120, activation='relu')),\n",
    "model_b.add(layers.Dense(84, activation='relu')),\n",
    "model_b.add(layers.Dense(10, activation='relu')),\n",
    "model_b.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_b = model_b.fit(X_train, y_train, batch_size=64, epochs=40, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_loss_acc(history_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_b_3 = model_b.evaluate(X_test, y_test)\n",
    "result_b_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution, 3 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=5, activation='relu', padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(layers.AveragePooling2D(pool_size=2, strides=2))\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=5, activation='relu'))\n",
    "model.add(layers.AveragePooling2D(pool_size=2, strides=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(120, activation='relu')),\n",
    "model.add(layers.Dense(84, activation='relu')),\n",
    "model.add(layers.Dense(10, activation='relu')),\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=40, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_c_3 = model.evaluate(X_test, y_test)\n",
    "result_c_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Baseline 1 Feature (CHL):', result_b_1)\n",
    "print('Convolution 1 Feature (CHL):', result_c_1)\n",
    "print('Baseline 3 Features:', result_b_3)\n",
    "print('Convolution 3 Features:', result_c_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv-kernel",
   "language": "python",
   "name": "local-venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
